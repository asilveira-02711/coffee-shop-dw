# Coffee Shop DW
# 
Projeto de construÃ§Ã£o de um Data Warehouse no Snowflake orquestrando as tarefas com Apache Airflow.
# 
# ğŸ“ Estrutura do Projeto
 
```
coffee-shop-dw/
â”œâ”€â”€ config/             # Arquivos de configuraÃ§Ã£o (atualmente vazio)
â”œâ”€â”€ dags/               # DAGs do Apache Airflow
â”‚   â””â”€â”€ dag_cafe_etl.py # DAG principal para carga no DW
â”œâ”€â”€ logs/               # DiretÃ³rio de logs gerados pelo Airflow
â”œâ”€â”€ plugins/            # Plugins customizados para o Airflow (atualmente vazio)
â”œâ”€â”€ docker-compose.yaml # OrquestraÃ§Ã£o dos serviÃ§os com Docker
â””â”€â”€ create_dw.sql       # Script SQL para criaÃ§Ã£o das tabelas no Snowflake
```
 
ğŸš€ Tecnologias e Ferramentas
 
- **Apache Airflow** (orquestraÃ§Ã£o de workflows)
- **Docker** (ambiente isolado e portÃ¡til)
- **Snowflake** (Data Warehouse)
- **Python** (desenvolvimento da DAG)
 
#ğŸ“¦ Requisitos para execuÃ§Ã£o local
 
- [Docker](https://www.docker.com/)
- [Docker Compose](https://docs.docker.com/compose/)
 
â–¶ï¸ Como executar o projeto

1. Clone este repositÃ³rio:

    ```
    git clone https://github.com/seu-usuario/coffee-shop-dw.git
    cd coffee-shop-dw
    ```

 2. Suba o ambiente com o Docker Compose:
 
    ```
    docker-compose up
    ```
 
 3. Acesse o Airflow via navegador:
 
    ```
    http://localhost:8080
    ```
    UsuÃ¡rio padrÃ£o: `airflow`  
    Senha: `airflow`
 
 4. Execute o script `create_dw.sql` diretamente no console do Snowflake para criar as tabelas do DW.
 
 5. Execute a DAG `dag_cafe_etl` manualmente ou agende conforme desejado.
 
 ğŸ“ ObservaÃ§Ãµes
 
 - As pastas `config/`, `logs/` e `plugins/` estÃ£o incluÃ­das propositalmente na estrutura, pois sÃ£o importantes para o funcionamento do Airflow mesmo que estejam vazias no inÃ­cio.
 - Arquivos `.gitkeep` sÃ£o utilizados para preservar essas pastas no controle de versÃ£o.
 
 ğŸ“š Sobre o projeto
 
 Este projeto foi desenvolvido como parte da disciplina de Engenharia de Dados na pÃ³s-graduaÃ§Ã£o
